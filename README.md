# ğŸ“ Emotion Detection for Online Classes using AWS Rekognition and Firebase

This project detects human emotions from facial expressions using AWS Rekognition and stores the results in a Firebase Realtime Database. It is designed primarily for monitoring student engagement in online learning environments by analyzing bulk images from classroom snapshots or individual webcam captures.

---

## ğŸ“Œ Features

- ğŸ¤– **Facial Emotion Recognition** using AWS Rekognition
- ğŸ”¥ **Firebase Integration** for real-time data storage
- âœ… Detects emotions like `HAPPY`, `SAD`, `ANGRY`, `CALM`, `SURPRISED`, `CONFUSED`, and `DISGUSTED`
- ğŸ’¾ Stores emotion data with timestamp and confidence score
- ğŸ” Logs each result with appropriate feedback

---

## ğŸ“‚ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ images/                      # Folder containing input images
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ detect_emotion.py        # Main script to detect and push emotions
â”‚   â”œâ”€â”€ serviceAccountKey.json   # Firebase credentials file
â”‚   â””â”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md                    # Project documentation
â””â”€â”€ screenshots/                 # Output screenshot folder
```

---

## ğŸš€ Technologies Used

- **AWS Rekognition** â€“ for facial analysis and emotion detection
- **Firebase Realtime Database** â€“ to store emotion results in real-time
- **Python 3.x**
- **OpenCV** â€“ for image preprocessing (optional, but useful)
- **Boto3** â€“ to interact with AWS Rekognition
- **firebase-admin** â€“ to interact with Firebase

---

## ğŸ› ï¸ Installation

### 1. Clone the repository

### 2. Set up a virtual environment (recommended)

```bash
python -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure AWS

Run the following to configure AWS credentials:

```bash
aws configure
```

You'll need to provide your **AWS Access Key ID**, **Secret Access Key**, region (e.g., `us-east-1`), and output format (`json`).

---

## ğŸ”‘ Firebase Setup

1. Go to [Firebase Console](https://console.firebase.google.com/)
2. Create a project and navigate to **Project Settings > Service Accounts**
3. Generate a private key (`serviceAccountKey.json`)
4. Save the file in the `code/` directory
5. Update the Firebase URL inside the Python script (`detect_emotion.py`)

---

## ğŸ“¸ How to Use

1. Add your test images in the `images/` folder.
2. Run the script:

```bash
python detect_emotion.py
```

3. Output will display detected emotions and upload confirmation.
4. Check Firebase Realtime Database to see the pushed data.

---

## ğŸ“Š Sample Output (Firebase Entry)

```json
{
  "student": "student1",
  "emotion": "happy",
  "confidence": 98.65,
  "timestamp": "2025-04-17T20:04:15.226940"
}
```

## ğŸ“ˆ Future Enhancements

- Real-time webcam integration using OpenCV
- Live dashboard for visualizing engagement
- Multi-label emotion detection
- Integration with classroom platforms like Google Meet or Zoom

---

## ğŸ“„ License

This project is for academic use only and not intended for commercial deployment without permission.

---

## ğŸ¤ Acknowledgements

- AWS Rekognition
- Firebase by Google
- Python Community

---

Feel free to fork, modify, and submit a pull request. Happy coding! ğŸ˜„
```

---

Let me know if you'd like to include a project logo, GitHub badges, or add deployment instructions (e.g., Streamlit, web integration).
